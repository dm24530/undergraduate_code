{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Paddle 白话第四篇—— 广播（broadcasting）\n",
    "PaddlePaddle和其他框架一样，提供的一些API支持广播(broadcasting)机制，允许在一些运算时使用不同形状的张量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 广播（broadcasting）\n",
    "解释：当两个数组的形状并不相同的时候，我们可以通过扩展数组的方法来实现相加、相减、相乘等操作\n",
    "Paddle在广播中与Numpy的广播机制类似，但是又有革新，让我们一起来看看吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 参考资料\n",
    "Paddle官网：[https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-rc/guides/01_paddle2.0_introduction/basic_concept/broadcasting_cn.html](https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-rc/guides/01_paddle2.0_introduction/basic_concept/broadcasting_cn.html)\n",
    "\n",
    "Numpy官网-广播机制：[https://numpy.org/doc/stable/user/basics.broadcasting.html#module-numpy.doc.broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html#module-numpy.doc.broadcasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### CSDN地址\n",
    "三岁白话系列CSDN地址：\n",
    "[https://blog.csdn.net/weixin_45623093/category_10616602.html](https://blog.csdn.net/weixin_45623093/category_10616602.html)\n",
    "\n",
    "paddlepaddleCSDN系列文章：[https://blog.csdn.net/PaddlePaddle](https://blog.csdn.net/PaddlePaddle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入第三方库\r\n",
    "import paddle\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 同维度的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= Tensor(shape=[2, 3, 4], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "y= Tensor(shape=[2, 3, 4], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "x+y= Tensor(shape=[2, 3, 4], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]]])\n",
      "x add y= Tensor(shape=[2, 3, 4], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]]])\n"
     ]
    }
   ],
   "source": [
    "# 同维度的操作\r\n",
    "x = paddle.to_tensor(np.ones((2, 3, 4), np.float32))\r\n",
    "y = paddle.to_tensor(np.ones((2, 3, 4), np.float32))\r\n",
    "print(\"x=\", x)\r\n",
    "print(\"y=\", y)\r\n",
    "print('x+y=', x+y)  # 逐元素相加\r\n",
    "print('x add y=', paddle.add(x, y))  # add API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 广播规则\n",
    "**为了进行广播，操作中两个阵列的尾轴尺寸必须相同，或者其中之一必须相同。**\n",
    "\n",
    "解析：\n",
    "\n",
    "如果两个数组的后缘维度（trailing dimension，即从末尾开始算起的维度）的轴长度相符，或其中的一方的长度为1，则认为它们是广播兼容的。广播会在缺失和（或）长度为1的维度上进行。\n",
    "\n",
    "  这句话乃是理解广播的核心。广播主要发生在两种情况，一种是两个数组的维数不相等，但是它们的后缘维度的轴长相符，另外一种是有一方的长度为1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 类型1：数组维度不同，后缘维度的轴长相符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 多维和一维广播操作\n",
    "多维和一维的操作要准守广播规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x+y= Tensor(shape=[3], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "x = paddle.to_tensor([1.0, 2.0, 3.0])\r\n",
    "y = paddle.to_tensor(2.0)\r\n",
    "print('x+y=', x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 原理\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/2c7cf46e9e5d49f991885c774738226c7a5309f96bed41b8b63a9f88a0c34851)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x+y Tensor(shape=[4, 3], dtype=int64, place=CPUPlace, stop_gradient=True,\n",
      "       [[1, 2, 3],\n",
      "        [2, 3, 4],\n",
      "        [3, 4, 5],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "x = paddle.to_tensor([[0, 0, 0],[1, 1, 1],[2, 2, 2], [3, 3, 3]])\r\n",
    "y = paddle.to_tensor([1, 2, 3])\r\n",
    "print('x+y', x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 原理：\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/11c941a0b6524f9aa0f6b680375ef865add45585271348d99eea17e284a04f56)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 错误示范：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = paddle.to_tensor([[ 0.0,  0.0,  0.0],\r\n",
    "...            [10.0, 10.0, 10.0],\r\n",
    "...            [20.0, 20.0, 20.0],\r\n",
    "...            [30.0, 30.0, 30.0]]) # 大小：4*3\r\n",
    "y = paddle.to_tensor([0, 1, 2, 3])  # 大小：4\r\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 问题解析\n",
    "报错情况：\n",
    "\n",
    "```\n",
    "EnforceNotMet: \n",
    "----------------------\n",
    "Error Message Summary:\n",
    "----------------------\n",
    "InvalidArgumentError: Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [4, 3] and the shape of Y = [4]. Received [3] in X is not equal to [4] in Y at i:1.\n",
    "  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:160)\n",
    "  [operator < elementwise_add > error]\n",
    "```\n",
    "\n",
    "### 问题\n",
    "没有符合广播原则，最后的维度没有对齐\n",
    "### 原理图:\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/402b63939b2a4ca1a9e501134949eedc1b570b525ac14a46affae58e35401180)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 多维度和多维度之间的广播\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x的形状 [3, 4, 2]\n",
      "y的形状 [4, 2]\n",
      "x+y Tensor(shape=[3, 4, 2], dtype=int64, place=CPUPlace, stop_gradient=True,\n",
      "       [[[0, 2],\n",
      "         [4, 6],\n",
      "         [ 8, 10],\n",
      "         [12, 14]],\n",
      "\n",
      "        [[0, 2],\n",
      "         [4, 6],\n",
      "         [ 8, 10],\n",
      "         [12, 14]],\n",
      "\n",
      "        [[0, 2],\n",
      "         [4, 6],\n",
      "         [ 8, 10],\n",
      "         [12, 14]]])\n"
     ]
    }
   ],
   "source": [
    "x = paddle.to_tensor([[[0, 1], [2, 3], [4, 5], [6,7]],\r\n",
    "                    [[0, 1], [2, 3], [4, 5], [6,7]],\r\n",
    "                    [[0, 1], [2, 3], [4, 5], [6,7]]])\r\n",
    "print('x的形状', x.shape)\r\n",
    "y = paddle.to_tensor([[0, 1], [2, 3], [4, 5], [6,7]])\r\n",
    "print('y的形状', y.shape)\r\n",
    "print('x+y', x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 原理\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0b4399cc051548eeabd89a4465a8f52020968a283e7b4cf4b6f1d32a1f03e55f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 类型二：数组维度相同，后缘维度的轴长不相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x+y Tensor(shape=[4, 3], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[0., 1., 2.],\n",
      "        [10., 11., 12.],\n",
      "        [20., 21., 22.],\n",
      "        [30., 31., 32.]])\n"
     ]
    }
   ],
   "source": [
    "x = paddle.to_tensor(([[0.0], [10.0], [20.0], [30.0]]))\r\n",
    "y = paddle.to_tensor([0.0, 1.0, 2.0])\r\n",
    "print('x+y', x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 原理：\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4ca9cedbc565490492353dffea85f34388f4b7cb3f7043c19406982fa4b01b6b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 特殊情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[3, 5, 6], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.]]])\n"
     ]
    }
   ],
   "source": [
    "x = paddle.to_tensor(np.ones((3, 5, 6), np.float32))\r\n",
    "y = paddle.to_tensor(np.ones((1, 6), np.float32))\r\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 解析：\n",
    "这个地方虽然数组维度不相同，后缘维度的轴长也不相同\n",
    "\n",
    "但是这里后缘维度不同的地方是1，也可以先把1进行处理\n",
    "\n",
    "让我们举例说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[3, 5, 6], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.]],\n",
      "\n",
      "        [[ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.]],\n",
      "\n",
      "        [[ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.],\n",
      "         [ 7.,  7.,  7.,  7.,  7., 17.]]])\n"
     ]
    }
   ],
   "source": [
    "x = paddle.to_tensor([[[2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.]],\r\n",
    "\r\n",
    "        [[2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.]],\r\n",
    "\r\n",
    "        [[2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.],\r\n",
    "         [2., 3., 4., 5., 6., 7.]]])\r\n",
    "\r\n",
    "y = paddle.to_tensor([[5, 4, 3, 2, 1, 10]])\r\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "看到这里都明白了什么吧！不懂也不解释了！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Paddle不一样的广播机制——\"elementwise\"\n",
    "飞桨的elementwise系列API针对广播机制增加了axis参数\n",
    "\n",
    "添加了axis参数以后广播的位置就可以进行自定义了（自定义开始位置）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[2, 3, 4], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]]])\n",
      "z的形状： [2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "paddle.disable_static()\r\n",
    "\r\n",
    "x = paddle.to_tensor(np.ones((2, 1, 4), np.float32))\r\n",
    "y = paddle.to_tensor(np.ones((3, 1), np.float32))\r\n",
    "z = paddle.fluid.layers.elementwise_add(x, y, axis=1)\r\n",
    "# z的形状 [2, 3, 4]\r\n",
    "print(z)\r\n",
    "print(\"z的形状：\", z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 白话原理：\n",
    "这里的广播虽然本来没有axis=1也可以正常运行，结果和这个是一样的\n",
    "\n",
    "这里的原理和之前说的特殊情况是一个道理，就是只要维度相同，其中一位等于1该维度就可以广播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paddle.disable_static()\r\n",
    "x = paddle.to_tensor(np.ones((2, 3, 4, 5), np.float32))\r\n",
    "y = paddle.to_tensor(np.ones((4, 5), np.float32))\r\n",
    "z = paddle.fluid.layers.elementwise_add(x, y, axis=1)\r\n",
    "print(z.shape)\r\n",
    "# InvalidArgumentError: Broadcast dimension mismatch.\r\n",
    "# 因为指定了axis之后，计算广播的维度从axis开始从前向后比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 白话解析\n",
    "报错内容：\n",
    "```\n",
    "EnforceNotMet: \n",
    "----------------------\n",
    "Error Message Summary:\n",
    "----------------------\n",
    "InvalidArgumentError: Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [2, 3, 4, 5] and the shape of Y = [4, 5]. Received [3] in X is not equal to [4] in Y at i:1.\n",
    "  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:160)\n",
    "  [operator < elementwise_add > error]\n",
    "```\n",
    "这里小的Tensor的维度4,5是和大的Tensor的后缘维度的轴长是相同的！！！\n",
    "\n",
    "但是这里面的axis设置了是1也就是从倒数第二个维度开始计算小的Tensor的是（4， 5）大的Tensor是（3， 4）\n",
    "\n",
    "维度不匹配，会产生以上的报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z的形状： [2, 3, 4, 5]\n",
      "Tensor(shape=[2, 3, 4, 5], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]]]])\n"
     ]
    }
   ],
   "source": [
    "paddle.disable_static()\r\n",
    "x = paddle.to_tensor(np.ones((2, 3, 4, 5), np.float32))\r\n",
    "y = paddle.to_tensor(np.ones((3), np.float32))\r\n",
    "z = paddle.fluid.layers.elementwise_add(x, y, axis=1)\r\n",
    "print(\"z的形状：\", z.shape)\r\n",
    "print(z)\r\n",
    "# z的形状 [2, 3, 4, 5]\r\n",
    "# 因为此时是从axis=1的维度开始，从前向后比较维度进行广播\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 白话解析\n",
    "这里的内容和上面的所法一样的\n",
    "\n",
    "就是虽然小Tensor的后缘维度的轴长和大的Tensor的后缘维度的轴长不同\n",
    "\n",
    "但是设置过axis=1以后小的后缘维度对应的是大的后缘维度的第二位就是相同的可以进行广播操作\n",
    "\n",
    "这里需要大家直行理解一下，白话的可能比较乱[尴尬]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 特殊说明\n",
    "广播提供了一种对数组操作进行矢量化的方法，从而使循环在C而不是Python中发生。这样做无需复制不必要的数据，通常可以实现高效的算法实现。在某些情况下，广播不是一个好主意，因为广播会导致内存使用效率低下，从而减慢计算速度。\n",
    "\n",
    "看情况量力而行 啦！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
